{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s2GHGJ1K1uh"
      },
      "source": [
        "## Лабораторная работа \"Линейные модели\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy-GsKMLK1uk"
      },
      "source": [
        "Некоторые задачи в этом ноутбуке надо будет сдавать в [контест](https://new.contest.yandex.ru/60377/start). Когда сдаете туда код, не забудьте сверху прописать все нужные импорты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjm0ejHfK1ul"
      },
      "source": [
        "Мы рассчитываем, что перед тем, как садиться за этот ноутбук, вы прочитали часть про регрессию главы \"Линейные модели\" хендбука по ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeK9RFdNK1ul"
      },
      "source": [
        "Начнём с загрузки необходимых библиотек и функций.\n",
        "\n",
        "Параметр `seed` будет использоваться далее для инициализации генератора случайных чисел из библиотеки `numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "ckp6TITPK1ul",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional, List\n",
        "\n",
        "import sklearn.base\n",
        "\n",
        "seed = 24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUoWdYEMK1um"
      },
      "source": [
        "В этом ноутбуке мы будем практиковаться на датасете [\"The Ames Iowa Housing Data\"](https://www.openml.org/d/41211). Здесь собраны описания и цены жилья в городе Эймс, штат Айова. Мы будем решать задачу предсказания цены (`Sale_Price`) по всем остальным признакам.\n",
        "\n",
        "И начнём мы, конечно, с того, что внимательно посмотрим на датасет: какие там есть объекты и какие признаки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "wB9CDwb6K1un",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.8.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1646k    0 1646k    0     0  1572k      0 --:--:--  0:00:-- --:--:-- 19906:01 --:--:-- 1585k\n"
          ]
        }
      ],
      "source": [
        "## Uncomment the line below to download data and install necessary packages\n",
        "## Maybe won't work on Windows :(\n",
        "\n",
        "%pip install numpy pandas scikit-learn matplotlib\n",
        "!curl https://api.openml.org/data/get_csv/20649135/file2ed11cebe25.arff > data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "-hZmDQonK1un",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MS_SubClass</th>\n",
              "      <th>MS_Zoning</th>\n",
              "      <th>Lot_Frontage</th>\n",
              "      <th>Lot_Area</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>Lot_Shape</th>\n",
              "      <th>Land_Contour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>Lot_Config</th>\n",
              "      <th>...</th>\n",
              "      <th>Fence</th>\n",
              "      <th>Misc_Feature</th>\n",
              "      <th>Misc_Val</th>\n",
              "      <th>Mo_Sold</th>\n",
              "      <th>Year_Sold</th>\n",
              "      <th>Sale_Type</th>\n",
              "      <th>Sale_Condition</th>\n",
              "      <th>Sale_Price</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Latitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2320</th>\n",
              "      <td>Two_Story_1946_and_Newer</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>42</td>\n",
              "      <td>13751</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Slightly_Irregular</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>CulDSac</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2006</td>\n",
              "      <td>New</td>\n",
              "      <td>Partial</td>\n",
              "      <td>309000</td>\n",
              "      <td>-93.635798</td>\n",
              "      <td>42.062891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>812</th>\n",
              "      <td>Duplex_All_Styles_and_Ages</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>64</td>\n",
              "      <td>7018</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Alloca</td>\n",
              "      <td>142953</td>\n",
              "      <td>-93.679097</td>\n",
              "      <td>42.031461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>920</th>\n",
              "      <td>Two_Story_1945_and_Older</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>0</td>\n",
              "      <td>7500</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Slightly_Irregular</td>\n",
              "      <td>Bnk</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>177500</td>\n",
              "      <td>-93.639700</td>\n",
              "      <td>42.019181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1839</th>\n",
              "      <td>One_Story_PUD_1946_and_Newer</td>\n",
              "      <td>Floating_Village_Residential</td>\n",
              "      <td>30</td>\n",
              "      <td>5330</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Paved</td>\n",
              "      <td>Moderately_Irregular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2007</td>\n",
              "      <td>New</td>\n",
              "      <td>Partial</td>\n",
              "      <td>207500</td>\n",
              "      <td>-93.646607</td>\n",
              "      <td>42.047699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097</th>\n",
              "      <td>Two_Story_1946_and_Newer</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>77</td>\n",
              "      <td>8390</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Slightly_Irregular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>185900</td>\n",
              "      <td>-93.640959</td>\n",
              "      <td>42.058581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>One_Story_1945_and_Older</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>56</td>\n",
              "      <td>4060</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>99900</td>\n",
              "      <td>-93.659191</td>\n",
              "      <td>42.021496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1275</th>\n",
              "      <td>One_and_Half_Story_Unfinished_All_Ages</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>59</td>\n",
              "      <td>7227</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>105500</td>\n",
              "      <td>-93.608765</td>\n",
              "      <td>42.034789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2550</th>\n",
              "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>80</td>\n",
              "      <td>10800</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>Minimum_Privacy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>151500</td>\n",
              "      <td>-93.622017</td>\n",
              "      <td>42.040143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>60</td>\n",
              "      <td>12450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>153000</td>\n",
              "      <td>-93.690159</td>\n",
              "      <td>42.037756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>Two_Story_1946_and_Newer</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>0</td>\n",
              "      <td>13142</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Slightly_Irregular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>215700</td>\n",
              "      <td>-93.689772</td>\n",
              "      <td>42.018786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960</th>\n",
              "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>60</td>\n",
              "      <td>7200</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>102000</td>\n",
              "      <td>-93.607963</td>\n",
              "      <td>42.035954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2200</th>\n",
              "      <td>One_and_Half_Story_Finished_All_Ages</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>60</td>\n",
              "      <td>7200</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>Minimum_Privacy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>175000</td>\n",
              "      <td>-93.646165</td>\n",
              "      <td>42.018921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1604</th>\n",
              "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>60</td>\n",
              "      <td>6600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>Minimum_Privacy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>130500</td>\n",
              "      <td>-93.603917</td>\n",
              "      <td>41.988110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>Split_or_Multilevel</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>0</td>\n",
              "      <td>15584</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>165000</td>\n",
              "      <td>-93.662126</td>\n",
              "      <td>42.032652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>One_and_Half_Story_Finished_All_Ages</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>51</td>\n",
              "      <td>6171</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>Minimum_Privacy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>137450</td>\n",
              "      <td>-93.648429</td>\n",
              "      <td>42.017835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1534</th>\n",
              "      <td>One_and_Half_Story_Finished_All_Ages</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>0</td>\n",
              "      <td>9260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Gravel</td>\n",
              "      <td>Slightly_Irregular</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>110000</td>\n",
              "      <td>-93.639497</td>\n",
              "      <td>42.018766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>110</td>\n",
              "      <td>14230</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>256300</td>\n",
              "      <td>-93.654241</td>\n",
              "      <td>42.062991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1669</th>\n",
              "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>0</td>\n",
              "      <td>7340</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Slightly_Irregular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>110000</td>\n",
              "      <td>-93.628050</td>\n",
              "      <td>42.053503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2294</th>\n",
              "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
              "      <td>Residential_Low_Density</td>\n",
              "      <td>61</td>\n",
              "      <td>33983</td>\n",
              "      <td>Pave</td>\n",
              "      <td>No_Alley_Access</td>\n",
              "      <td>Slightly_Irregular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>Good_Privacy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>196000</td>\n",
              "      <td>-93.606780</td>\n",
              "      <td>41.990264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1835</th>\n",
              "      <td>One_Story_PUD_1946_and_Newer</td>\n",
              "      <td>Floating_Village_Residential</td>\n",
              "      <td>80</td>\n",
              "      <td>3523</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Paved</td>\n",
              "      <td>Slightly_Irregular</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>No_Fence</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2007</td>\n",
              "      <td>New</td>\n",
              "      <td>Partial</td>\n",
              "      <td>166000</td>\n",
              "      <td>-93.647330</td>\n",
              "      <td>42.047425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 MS_SubClass                     MS_Zoning  \\\n",
              "2320                Two_Story_1946_and_Newer       Residential_Low_Density   \n",
              "812               Duplex_All_Styles_and_Ages       Residential_Low_Density   \n",
              "920                 Two_Story_1945_and_Older       Residential_Low_Density   \n",
              "1839            One_Story_PUD_1946_and_Newer  Floating_Village_Residential   \n",
              "1097                Two_Story_1946_and_Newer       Residential_Low_Density   \n",
              "897                 One_Story_1945_and_Older       Residential_Low_Density   \n",
              "1275  One_and_Half_Story_Unfinished_All_Ages       Residential_Low_Density   \n",
              "2550     One_Story_1946_and_Newer_All_Styles       Residential_Low_Density   \n",
              "541      One_Story_1946_and_Newer_All_Styles       Residential_Low_Density   \n",
              "1435                Two_Story_1946_and_Newer       Residential_Low_Density   \n",
              "1960     One_Story_1946_and_Newer_All_Styles       Residential_Low_Density   \n",
              "2200    One_and_Half_Story_Finished_All_Ages       Residential_Low_Density   \n",
              "1604     One_Story_1946_and_Newer_All_Styles       Residential_Low_Density   \n",
              "779                      Split_or_Multilevel       Residential_Low_Density   \n",
              "913     One_and_Half_Story_Finished_All_Ages       Residential_Low_Density   \n",
              "1534    One_and_Half_Story_Finished_All_Ages       Residential_Low_Density   \n",
              "425      One_Story_1946_and_Newer_All_Styles       Residential_Low_Density   \n",
              "1669     One_Story_1946_and_Newer_All_Styles       Residential_Low_Density   \n",
              "2294     One_Story_1946_and_Newer_All_Styles       Residential_Low_Density   \n",
              "1835            One_Story_PUD_1946_and_Newer  Floating_Village_Residential   \n",
              "\n",
              "      Lot_Frontage  Lot_Area Street            Alley             Lot_Shape  \\\n",
              "2320            42     13751   Pave  No_Alley_Access    Slightly_Irregular   \n",
              "812             64      7018   Pave  No_Alley_Access               Regular   \n",
              "920              0      7500   Pave  No_Alley_Access    Slightly_Irregular   \n",
              "1839            30      5330   Pave            Paved  Moderately_Irregular   \n",
              "1097            77      8390   Pave  No_Alley_Access    Slightly_Irregular   \n",
              "897             56      4060   Pave  No_Alley_Access               Regular   \n",
              "1275            59      7227   Pave  No_Alley_Access               Regular   \n",
              "2550            80     10800   Pave  No_Alley_Access               Regular   \n",
              "541             60     12450   Pave  No_Alley_Access               Regular   \n",
              "1435             0     13142   Pave  No_Alley_Access    Slightly_Irregular   \n",
              "1960            60      7200   Pave  No_Alley_Access               Regular   \n",
              "2200            60      7200   Pave  No_Alley_Access               Regular   \n",
              "1604            60      6600   Pave  No_Alley_Access               Regular   \n",
              "779              0     15584   Pave  No_Alley_Access               Regular   \n",
              "913             51      6171   Pave  No_Alley_Access               Regular   \n",
              "1534             0      9260   Pave           Gravel    Slightly_Irregular   \n",
              "425            110     14230   Pave  No_Alley_Access               Regular   \n",
              "1669             0      7340   Pave  No_Alley_Access    Slightly_Irregular   \n",
              "2294            61     33983   Pave  No_Alley_Access    Slightly_Irregular   \n",
              "1835            80      3523   Pave            Paved    Slightly_Irregular   \n",
              "\n",
              "     Land_Contour Utilities Lot_Config  ...            Fence Misc_Feature  \\\n",
              "2320          HLS    AllPub    CulDSac  ...         No_Fence          NaN   \n",
              "812           Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
              "920           Bnk    AllPub     Inside  ...         No_Fence          NaN   \n",
              "1839          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
              "1097          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
              "897           Lvl    AllPub     Corner  ...         No_Fence          NaN   \n",
              "1275          HLS    AllPub     Corner  ...         No_Fence          NaN   \n",
              "2550          Lvl    AllPub     Inside  ...  Minimum_Privacy          NaN   \n",
              "541           Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
              "1435          Lvl    AllPub     Corner  ...         No_Fence          NaN   \n",
              "1960          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
              "2200          Lvl    AllPub     Corner  ...  Minimum_Privacy          NaN   \n",
              "1604          Lvl    AllPub     Inside  ...  Minimum_Privacy          NaN   \n",
              "779           Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
              "913           Lvl    AllPub     Inside  ...  Minimum_Privacy          NaN   \n",
              "1534          HLS    AllPub     Inside  ...         No_Fence          NaN   \n",
              "425           Lvl    AllPub     Corner  ...         No_Fence          NaN   \n",
              "1669          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
              "2294          Lvl    AllPub     Inside  ...     Good_Privacy          NaN   \n",
              "1835          Lvl    AllPub     Inside  ...         No_Fence          NaN   \n",
              "\n",
              "     Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition Sale_Price  \\\n",
              "2320        0       5      2006       New        Partial     309000   \n",
              "812         0       6      2009       WD          Alloca     142953   \n",
              "920         0      11      2009       WD          Normal     177500   \n",
              "1839        0       7      2007       New        Partial     207500   \n",
              "1097        0       5      2008       WD          Normal     185900   \n",
              "897         0       7      2009       WD          Normal      99900   \n",
              "1275        0       6      2008       WD          Normal     105500   \n",
              "2550        0       5      2006       WD          Normal     151500   \n",
              "541         0       6      2009       WD          Normal     153000   \n",
              "1435        0       7      2008       WD          Normal     215700   \n",
              "1960        0      11      2007       WD          Normal     102000   \n",
              "2200        0       6      2007       WD          Normal     175000   \n",
              "1604        0      10      2008       WD          Normal     130500   \n",
              "779         0      10      2009       WD          Normal     165000   \n",
              "913         0      10      2009       WD          Normal     137450   \n",
              "1534        0       3      2008       WD          Normal     110000   \n",
              "425         0       7      2009       WD          Normal     256300   \n",
              "1669        0       6      2007       WD          Normal     110000   \n",
              "2294        0       5      2007       WD          Normal     196000   \n",
              "1835        0       2      2007       New        Partial     166000   \n",
              "\n",
              "      Longitude   Latitude  \n",
              "2320 -93.635798  42.062891  \n",
              "812  -93.679097  42.031461  \n",
              "920  -93.639700  42.019181  \n",
              "1839 -93.646607  42.047699  \n",
              "1097 -93.640959  42.058581  \n",
              "897  -93.659191  42.021496  \n",
              "1275 -93.608765  42.034789  \n",
              "2550 -93.622017  42.040143  \n",
              "541  -93.690159  42.037756  \n",
              "1435 -93.689772  42.018786  \n",
              "1960 -93.607963  42.035954  \n",
              "2200 -93.646165  42.018921  \n",
              "1604 -93.603917  41.988110  \n",
              "779  -93.662126  42.032652  \n",
              "913  -93.648429  42.017835  \n",
              "1534 -93.639497  42.018766  \n",
              "425  -93.654241  42.062991  \n",
              "1669 -93.628050  42.053503  \n",
              "2294 -93.606780  41.990264  \n",
              "1835 -93.647330  42.047425  \n",
              "\n",
              "[20 rows x 81 columns]"
            ]
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('./data.csv')\n",
        "\n",
        "data.sample(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "KP3ImCtGK1uo",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2930 entries, 0 to 2929\n",
            "Data columns (total 81 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   MS_SubClass         2930 non-null   object \n",
            " 1   MS_Zoning           2930 non-null   object \n",
            " 2   Lot_Frontage        2930 non-null   int64  \n",
            " 3   Lot_Area            2930 non-null   int64  \n",
            " 4   Street              2930 non-null   object \n",
            " 5   Alley               2930 non-null   object \n",
            " 6   Lot_Shape           2930 non-null   object \n",
            " 7   Land_Contour        2930 non-null   object \n",
            " 8   Utilities           2930 non-null   object \n",
            " 9   Lot_Config          2930 non-null   object \n",
            " 10  Land_Slope          2930 non-null   object \n",
            " 11  Neighborhood        2930 non-null   object \n",
            " 12  Condition_1         2930 non-null   object \n",
            " 13  Condition_2         2930 non-null   object \n",
            " 14  Bldg_Type           2930 non-null   object \n",
            " 15  House_Style         2930 non-null   object \n",
            " 16  Overall_Qual        2930 non-null   object \n",
            " 17  Overall_Cond        2930 non-null   object \n",
            " 18  Year_Built          2930 non-null   int64  \n",
            " 19  Year_Remod_Add      2930 non-null   int64  \n",
            " 20  Roof_Style          2930 non-null   object \n",
            " 21  Roof_Matl           2930 non-null   object \n",
            " 22  Exterior_1st        2930 non-null   object \n",
            " 23  Exterior_2nd        2930 non-null   object \n",
            " 24  Mas_Vnr_Type        1155 non-null   object \n",
            " 25  Mas_Vnr_Area        2930 non-null   int64  \n",
            " 26  Exter_Qual          2930 non-null   object \n",
            " 27  Exter_Cond          2930 non-null   object \n",
            " 28  Foundation          2930 non-null   object \n",
            " 29  Bsmt_Qual           2930 non-null   object \n",
            " 30  Bsmt_Cond           2930 non-null   object \n",
            " 31  Bsmt_Exposure       2930 non-null   object \n",
            " 32  BsmtFin_Type_1      2930 non-null   object \n",
            " 33  BsmtFin_SF_1        2930 non-null   int64  \n",
            " 34  BsmtFin_Type_2      2930 non-null   object \n",
            " 35  BsmtFin_SF_2        2930 non-null   int64  \n",
            " 36  Bsmt_Unf_SF         2930 non-null   int64  \n",
            " 37  Total_Bsmt_SF       2930 non-null   int64  \n",
            " 38  Heating             2930 non-null   object \n",
            " 39  Heating_QC          2930 non-null   object \n",
            " 40  Central_Air         2930 non-null   object \n",
            " 41  Electrical          2930 non-null   object \n",
            " 42  First_Flr_SF        2930 non-null   int64  \n",
            " 43  Second_Flr_SF       2930 non-null   int64  \n",
            " 44  Low_Qual_Fin_SF     2930 non-null   int64  \n",
            " 45  Gr_Liv_Area         2930 non-null   int64  \n",
            " 46  Bsmt_Full_Bath      2930 non-null   int64  \n",
            " 47  Bsmt_Half_Bath      2930 non-null   int64  \n",
            " 48  Full_Bath           2930 non-null   int64  \n",
            " 49  Half_Bath           2930 non-null   int64  \n",
            " 50  Bedroom_AbvGr       2930 non-null   int64  \n",
            " 51  Kitchen_AbvGr       2930 non-null   int64  \n",
            " 52  Kitchen_Qual        2930 non-null   object \n",
            " 53  TotRms_AbvGrd       2930 non-null   int64  \n",
            " 54  Functional          2930 non-null   object \n",
            " 55  Fireplaces          2930 non-null   int64  \n",
            " 56  Fireplace_Qu        2930 non-null   object \n",
            " 57  Garage_Type         2930 non-null   object \n",
            " 58  Garage_Finish       2930 non-null   object \n",
            " 59  Garage_Cars         2930 non-null   int64  \n",
            " 60  Garage_Area         2930 non-null   int64  \n",
            " 61  Garage_Qual         2930 non-null   object \n",
            " 62  Garage_Cond         2930 non-null   object \n",
            " 63  Paved_Drive         2930 non-null   object \n",
            " 64  Wood_Deck_SF        2930 non-null   int64  \n",
            " 65  Open_Porch_SF       2930 non-null   int64  \n",
            " 66  Enclosed_Porch      2930 non-null   int64  \n",
            " 67  Three_season_porch  2930 non-null   int64  \n",
            " 68  Screen_Porch        2930 non-null   int64  \n",
            " 69  Pool_Area           2930 non-null   int64  \n",
            " 70  Pool_QC             2930 non-null   object \n",
            " 71  Fence               2930 non-null   object \n",
            " 72  Misc_Feature        106 non-null    object \n",
            " 73  Misc_Val            2930 non-null   int64  \n",
            " 74  Mo_Sold             2930 non-null   int64  \n",
            " 75  Year_Sold           2930 non-null   int64  \n",
            " 76  Sale_Type           2930 non-null   object \n",
            " 77  Sale_Condition      2930 non-null   object \n",
            " 78  Sale_Price          2930 non-null   int64  \n",
            " 79  Longitude           2930 non-null   float64\n",
            " 80  Latitude            2930 non-null   float64\n",
            "dtypes: float64(2), int64(33), object(46)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjxpXT4xK1uo"
      },
      "source": [
        "Разобьём данные на обучающую и тестовую выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "aoC9zcGAK1uo",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train : (2344, 80) (2344,)\n",
            "Test : (586, 80) (586,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target_column = \"Sale_Price\"\n",
        "np.random.seed(seed)\n",
        "\n",
        "test_size = 0.2\n",
        "data_train, data_test, Y_train, Y_test = train_test_split(\n",
        "    data[data.columns.drop(\"Sale_Price\")],\n",
        "    np.array(data[\"Sale_Price\"]),\n",
        "    test_size=test_size,\n",
        "    random_state=seed)\n",
        "\n",
        "print(f\"Train : {data_train.shape} {Y_train.shape}\")\n",
        "print(f\"Test : {data_test.shape} {Y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNCvCJaAK1uo"
      },
      "source": [
        "Среди признаков нам встретятся как вещественные, так и категориальные. Пока что выделим в качестве категориальных те, значениями которых являются не числа, а какие-то другие сущности (но имейте в виду, что численные с виду признаки тоже могут быть категориальными)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "QK9MTesIK1up",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Continuous : 34, Categorical : 46\n"
          ]
        }
      ],
      "source": [
        "continuous_columns = [key for key in data.keys() if data[key].dtype in (\"int64\", \"float64\")]\n",
        "categorical_columns = [key for key in data.keys() if data[key].dtype == \"object\"]\n",
        "\n",
        "continuous_columns.remove(target_column)\n",
        "\n",
        "print(f\"Continuous : {len(continuous_columns)}, Categorical : {len(categorical_columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEjtSzMcK1up"
      },
      "source": [
        "Посмотрим на заголовки признаков. В целом, многие названия вполне говорящие, и можно догадаться, что стоит за этими признаками."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "L_PprkEPK1up",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Lot_Frontage',\n",
              " 'Lot_Area',\n",
              " 'Year_Built',\n",
              " 'Year_Remod_Add',\n",
              " 'Mas_Vnr_Area',\n",
              " 'BsmtFin_SF_1',\n",
              " 'BsmtFin_SF_2',\n",
              " 'Bsmt_Unf_SF',\n",
              " 'Total_Bsmt_SF',\n",
              " 'First_Flr_SF',\n",
              " 'Second_Flr_SF',\n",
              " 'Low_Qual_Fin_SF',\n",
              " 'Gr_Liv_Area',\n",
              " 'Bsmt_Full_Bath',\n",
              " 'Bsmt_Half_Bath',\n",
              " 'Full_Bath',\n",
              " 'Half_Bath',\n",
              " 'Bedroom_AbvGr',\n",
              " 'Kitchen_AbvGr',\n",
              " 'TotRms_AbvGrd',\n",
              " 'Fireplaces',\n",
              " 'Garage_Cars',\n",
              " 'Garage_Area',\n",
              " 'Wood_Deck_SF',\n",
              " 'Open_Porch_SF',\n",
              " 'Enclosed_Porch',\n",
              " 'Three_season_porch',\n",
              " 'Screen_Porch',\n",
              " 'Pool_Area',\n",
              " 'Misc_Val',\n",
              " 'Mo_Sold',\n",
              " 'Year_Sold',\n",
              " 'Longitude',\n",
              " 'Latitude']"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "continuous_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSh9iDYUK1up"
      },
      "source": [
        "Одна из целей этого ноутбука — познакомить вас с fit-predict (fit-transform) интерфейсом, типичным для многих реализаций моделей машинного обучения и для различных инструментов работы с данными.\n",
        "\n",
        "Множество фреймворков машинного обучения (например, scikit-learn, CatBoost) содержат в себе модели и алгоритмы, которые описаны в виде классов, у которых есть два ключевых метода: fit и predict (transform). Давайте разберёмся, что делают эти методы.\n",
        "\n",
        "***fit*** — метод для обучения алгоритма. Он получает на входе данные и таргеты для обучения, после чего обновляет состояние класса. После использования метода fit считается, что объект класса готов к использованию. Внутри этого метода может быть что угодно: обучение модели, подбор гиперпараметров, подсчет статистик и т. д.\n",
        "\n",
        "***predict*** — метод для предсказания , обученного с помощью _fit_. В задаче регрессии это оценка параметра, в задаче классификации предсказанный класс.\n",
        "\n",
        "***transform*** — стилистический синоним _predict_, но используется в классах, которые реализуют преобразования данных, например, масштабирование признаков или кодирование категориальных фичей.\n",
        "\n",
        "***fit_transform*** — метод который учится на данных, а потом их же преобразовывает."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QVOr2SrK1up"
      },
      "source": [
        "### 1. Базовая предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWi5LNwHK1up"
      },
      "source": [
        "Отметим два важных свойства линейной регрессии:\n",
        "\n",
        "- строго говоря, она умеет работать только с вещественными признаками\n",
        "- если признаки имеют разный масштаб при сопоставимой важности, регрессия может проигнорировать те, что имеют меньший масштаб\n",
        "\n",
        "Первое соображение заставляет придумывать способы борьбы с категориальными признаками, и мы начнём с самого простого: проигнорируем их.\n",
        "\n",
        "Второе соображение приводит к необходимости приводить признаки к одному масштабу (\"нормализовать фичи\"). В `sklearn` для этого есть два основных класса:\n",
        "\n",
        "- [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) - в каждой колонке вычитает среднее и делит на стандартное отклонение.\n",
        "- [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) - в каждой колонке вычитает минимальное значение и делит на разницу между минимальным и максимальным.\n",
        "\n",
        "Применяются они в соответствии с описанной выше философией. Например:\n",
        "\n",
        "```\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "```\n",
        "\n",
        "Обратите внимание, что scaler настраивается на обучающей выборке (именно по ней вычисляются среднее и стандартное отклонение), а к тестовой он применяется с уже подсчитанными статистиками.\n",
        "\n",
        "**Вопрос**. А зачем? Почему бы не нормировать отдельно обучающую и тестовую выборку? Почему бы не настроить наш scaler на объединении двух выборок? Ведь благодаря большему количеству данных мы бы настроили его точнее!\n",
        "<p>\n",
        "<details>\n",
        "  <summary>Кликните, чтобы узнать ответ</summary>\n",
        "\n",
        "Если мы по-разному отнормируем обучающую и тестовую выборки, то нам будет весьма сложно применять модель, обученную на одной из них, к другой. Это просто не будет иметь физического смысла.\n",
        "\n",
        "Настраивать что-либо на тестовой выборке — это очень плохая идея. Тестовая выборка должна быть неким независимым мерилом качества наших усилий по предсказанию, а если мы разрешим информации о распределении признаков в тестовой выборке \"протечь\" в процесс обучения, то мы эту независимость испортим.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "refOuBa2K1up"
      },
      "source": [
        "Итак, мы решили делать преобразование данных, которое состоит в:\n",
        "\n",
        "- сохранении лишь непрерывных фичей;\n",
        "- нормализации этих фичей (давайте остановимся на [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html))\n",
        "\n",
        "В этом пункте вам нужно будет сделать класс такой предобработки данных, причём оформим мы его в виде класса с интерфейсом fit-transform.\n",
        "\n",
        "Несколько важных соображений:\n",
        "\n",
        "1. В прошлой лабораторной метод fit у нас ничего не возвращал, но правильнее сделать так, чтобы метод fit возвращал сам класс. В частности, это позволит нам писать model = model.fit().\n",
        "\n",
        "2. Первоначальный анализ данных удобно делать, когда они лежат в pd.DataFrame, т к у этого класса много методов, которые малым количеством телодвижений позволяют считать статистики и строить графики. Модели же проще учить, когда данные лежат в np.array, потому большое количество библиотек, где реализованы алгоритмы машинного обучения совместимы именно с numpy. Поэтому сделайте так, чтобы метод transform получал на вход pd.Dataframe, а возвращал np.array.\n",
        "\n",
        "3. В sklearn есть классы, от которых можно отнаследоваться, чтобы сделать класс с [fit-predict](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin) или [fit-transform](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) интерфейсом. Это очень полезно, т к позволит вам в дальнейшем пользоваться методами [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) и подобными. В этом пункте отнаследуйтесь от второго.\n",
        "\n",
        "4. У метода __init__ должен быть параметр ```needed_columns=None```. Туда передается список колонок, которые нужно взять из датафрейме. Делать это надо в ```fit``` и ```transform```. В случае если если он равен None, то класс оставляет все колонки из исходного набора данных.\n",
        "\n",
        "5. Обратите внимание, что достаточно реализовать `fit` и `transform`, а метод `fit_transform` из них слепит родительский класс.\n",
        "\n",
        "**Готовый препроцессор вам нужно будет сдать в Контест**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "deONxYcGK1uq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "class BaseDataPreprocessor(TransformerMixin):\n",
        "    def __init__(self, needed_columns: Optional[List[str]]=None):\n",
        "        \"\"\"\n",
        "        :param needed_columns: if not None select these columns from the dataframe\n",
        "        \"\"\"\n",
        "        self.needed_columns = needed_columns\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def fit(self, data, *args):\n",
        "        \"\"\"\n",
        "        Prepares the class for future transformations\n",
        "        :param data: pd.DataFrame with all available columns\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        if self.needed_columns is not None:\n",
        "            data = data[self.needed_columns]\n",
        "        self.scaler.fit(data)\n",
        "        return self\n",
        "\n",
        "    def transform(self, data: pd.DataFrame) -> np.array:\n",
        "        \"\"\"\n",
        "        Transforms features so that they can be fed into the regressors\n",
        "        :param data: pd.DataFrame with all available columns\n",
        "        :return: np.array with preprocessed features\n",
        "        \"\"\"\n",
        "        if self.needed_columns is not None: \n",
        "            data = data[self.needed_columns]\n",
        "        data = self.scaler.transform(data)\n",
        "        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Логика использования fit и transform:\n",
        "\n",
        "Сначала вызывается fit, чтобы вычислить средние значения и стандартные отклонения по обучающим данным.\n",
        "\n",
        "Затем transform применяет эти вычисленные параметры для преобразования новых данных, что позволяет гарантировать, что данные находятся в одной и той же шкале, когда они передаются в модель для предсказания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В текущей реализации метода transform возвращается объект типа np.array, а не pd.DataFrame потому что метод transform класса StandardScaler из библиотеки scikit-learn возвращает именно массив NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Наследование от TransformerMixin предоставляет метод fit_transform, который сочетает в себе fit и transform в одном вызове. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Также можно добавить BaseEstimator, который предоставляет методы get_params и set_params. Это позволяет легко изменять параметры и использовать наш класс в гиперпараметрической оптимизации, например, с GridSearchCV или RandomizedSearchCV:\n",
        "```\n",
        "from sklearn.base import BaseEstimator\n",
        "class BaseDataPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    ...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKeWoQ1SK1uq"
      },
      "source": [
        "**1. Сдайте вашу реализацию в Контест, задача «Простая предобработка».**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "-4LkDFASK1uq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "preprocessor = BaseDataPreprocessor(needed_columns=continuous_columns)\n",
        "\n",
        "X_train = preprocessor.fit_transform(data_train)\n",
        "X_test = preprocessor.transform(data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p14ruXEjK1uq"
      },
      "source": [
        "### 1.2 Умная предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8erGdYK-K1uq"
      },
      "source": [
        "Теперь давайте попробуем сделать что-нибудь поинтереснее. Для того, чтобы будущие алгоритмы регрессии работали хорошо, они должны обучаться и предсказывать на информативных фичах. Зачастую оказывается гораздо продуктивнее потратить какое-то время на изучение предметной области и придумывание хороших фичей (feature engineering), нежели жадно перебирать все известные алгоритмы машинного обучения.\n",
        "В этом пункте попробуйте придумать новых фичей и написать новый класс предобработки данных, который их добавляет (а, возможно, и убирает ещё какие-то старые).\n",
        "\n",
        "В конце этого пункта в раскрывашке перечислены наши идеи относительно того, что можно было добавить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "Ob8_T-DRK1uq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class SmartDataPreprocessor(TransformerMixin):\n",
        "    def __init__(self, needed_columns: Optional[List[str]] = None):\n",
        "        self.scalar = StandardScaler()\n",
        "        self.needed_columns = needed_columns\n",
        "        self.city_center_coords = (42.034534, -93.620369)\n",
        "        self.median_lot_frontage = None\n",
        "        self.median_distance_from_city_center = None\n",
        "\n",
        "    # Этот метод вычисляет расстояние между двумя точками на поверхности Земли, \n",
        "    # используя формулу Гаверсина. Она принимает широту и долготу двух точек \n",
        "    # (одна из которых является центром города), и возвращает расстояние между \n",
        "    # этими точками в километрах.\n",
        "    def haversine(self, lat1, lon1, lat2, lon2):\n",
        "        from math import radians, cos, sin, sqrt, atan2\n",
        "        R = 6371  # радиус Земли (км)\n",
        "        dlat = radians(lat2 - lat1)\n",
        "        dlon = radians(lat2 - lon1)\n",
        "        a = sin(dlat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2) ** 2\n",
        "        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "        distance = R * c\n",
        "        return distance\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.median_lot_frontage = X['Lot_Frontage'].median()\n",
        "        self.median_distance_from_city_center = X.apply(\n",
        "            lambda row: self.haversine(row['Latitude'], row['Longitude'], self.city_center_coords[0], self.city_center_coords[1]), axis=1).median()\n",
        "        # X.apply(...).median() это просто числовое значение\n",
        "        \n",
        "        self.scalar.fit(X[self.needed_columns])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # add new features\n",
        "        X['House_Age'] = X['Year_Sold'] - X['Year_Built']\n",
        "        X['Remodel_Age'] = X['Year_Sold'] - X['Year_Remod_Add']\n",
        "        X['Total_Square_Footage'] = X['First_Flr_SF'] + X['Second_Flr_SF'] + X['Total_Bsmt_SF']\n",
        "        X['Has_FirePlace'] = X['Fireplaces'] > 0\n",
        "        X['Has_Pool'] = X['Pool_Area'] > 0\n",
        "\n",
        "        # добавляем новый столбец в DataFrame X, который называется Distance_From_City_Center\n",
        "        X['Distance_From_City_Center'] = X.apply(\n",
        "            lambda row: self.haversine(row['Latitude'], row['Longitude'], self.city_center_coords[0], self.city_center_coords[1]), axis=1)\n",
        "        # X.apply(...) имеет тип данных Series\n",
        "\n",
        "        # Заполняем пропущенные значения в колонке расстояний медианой, рассчитанной в методе fit.\n",
        "        X['Distance_From_City_Center'].fillna(self.median_distance_from_city_center, inplace=True)\n",
        "        \n",
        "        # Заполняем пропущенные значения в колонке Lot_Frontage медианой, рассчитанной в методе fit.\n",
        "        X['Lot_Frontage'].fillna(self.median_lot_frontage, inplace=True)\n",
        "        \n",
        "        # Оставляем только нужные колонки, указанные в needed_columns.\n",
        "        X = X[self.needed_columns]\n",
        "        \n",
        "        # Масштабируем данные\n",
        "        X = self.scalar.transform(X)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Метод 'fit' используется для вычисления необходимых статистик, таких как медианы и параметры масштабирования, которые зависят от обучающего набора данных. В этом методе вы подготавливаете все, что потребуется для трансформации данных, но не изменяете сами данные.\n",
        "\n",
        "Метод 'transform' используется для фактического преобразования набора данных, применяя вычисленные статистики и добавляя новые признаки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "ceqVElj8K1uq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# preprocessor = SmartDataPreprocessor(needed_columns=continuous_columns)\n",
        "#\n",
        "# X_train = preprocessor.fit_transform(data_train)\n",
        "# X_test = preprocessor.transform(data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCZ-Ud9OK1ur"
      },
      "source": [
        "<details>\n",
        "  <summary>Пара простых идей. Кликните, когда будете готовы</summary>\n",
        "\n",
        "Например в датасете есть координаты квартиры, которые по идее сами по себе мало чего дают нашему регрессору. С другой стороны, по ним можно оценить центр города (или просто найти его на карте) и использовать в качестве фичи расстояние до центра города, которое может естественным образом влиять на цену жилья.\n",
        "\n",
        "Ещё может быть полезным почистить пропуски. И тут есть хитрость. Если вы просто вызовете data.info(), то вам покажется, что пропусков нет, но они могут приходить под разными обличьями. Например, у 490 объектов параметр Lot_Frontage (площадь фасада) равен нулю. Неожиданно, правда? Возможно, мы хотим эти нулевые значения заменить чем-нибудь, скажем, медианой.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIt68R29K1ur"
      },
      "source": [
        "### 2. Линейная регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydi2yHwqK1ur"
      },
      "source": [
        "Давайте получим базовое решение (бейзлайн), чтобы потом с ним можно было сравниваться.\n",
        "\n",
        "Обучите линейную регрессию на обучающей выборке (которую мы подвергли преобразованию BaseDataPreprocessor). В библиотеке Sklearn есть релизация [без регуляризации](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression), [с L2-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) и [с L1-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso).\n",
        "\n",
        "Начнём с обычной регрессии. Получите предсказания на тестовых данных и оцените на них качество модели. В качестве метрики оценки качества возьмите [средний модуль отклонения](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) (mean absolute error, MAE). Как вам кажется, насколько хорошей вышла модель?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "d8AAt9_tK1ur",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE (no regularization) = 2522960657.734511\n"
          ]
        }
      ],
      "source": [
        "# Без регуляризации\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, Y_train)\n",
        "Y_pred_reg = lin_reg.predict(X_test)\n",
        "\n",
        "print(\"MAE (no regularization) =\", mean_squared_error(Y_test, Y_pred_reg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE (L1) = 2522935755.966237\n"
          ]
        }
      ],
      "source": [
        "# L1 регуляризация\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso_reg = Lasso(alpha=0.1)  # Параметр alpha контролирует степень регуляризации\n",
        "lasso_reg.fit(X_train, Y_train)\n",
        "Y_pred_lasso = lasso_reg.predict(X_test)\n",
        "\n",
        "print(\"MAE (L1) =\", mean_squared_error(Y_test, Y_pred_lasso))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js3L8W-AK1ur"
      },
      "source": [
        "Теперь попробуйте L2-регуляризованную модель Ridge(). Какие значения метрик она даёт?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "XnMAW-74K1ur",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE (L2) = 2522787309.8872004\n"
          ]
        }
      ],
      "source": [
        "# L2 регуляризация\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_reg = Ridge(alpha=0.1)\n",
        "ridge_reg.fit(X_train, Y_train)\n",
        "Y_pred_ridge = ridge_reg.predict(X_test)\n",
        "\n",
        "print(\"MAE (L2) =\", mean_squared_error(Y_test, Y_pred_ridge))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s940mdAmK1ur"
      },
      "source": [
        "В целом, регуляризация редко портит модель, но важно правильно подобрать коэффициент регуляризации. Как именно — поговорим дальше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iTC8BpaK1ur"
      },
      "source": [
        "### 3. Выбор метрики"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpjjz37cK1ur"
      },
      "source": [
        "Средний модуль ошибки (MAE) — в целом довольно хорошая метрика для задачи регрессии, потому что ее довольно легко проинтерпретировать. Но с ней есть одна проблема: ошибиться на $ 10 000 $ USD в предсказании цены квартиры стоимостью $ 100 000 $ USD страшнее чем допустить такую ошибку в предсказании цены жилья за $ 700 000 $ USD. Иными словами более показательной метрикой будет не абсолютная  ошибка $ error_i = |y_i - \\hat{y_i}|$, а логарифм относительной ошибки $error_i = log \\frac{y_i}{\\hat{y_i}} $. Также давайте обычное усреднение по всем примерам в тестовой выборке заменим на среднеквадратичное $ \\frac{1}{N} \\sum_i^{test} {error_i} \\longrightarrow \\sqrt{\\frac{1}{N} \\sum_i^{test}{(error_i)^2}}$. Итоговая метрика получается равной:\n",
        "\n",
        "$$\n",
        "Metric = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (log(y_i) - log(\\hat{y_i}))^2}\n",
        "$$\n",
        "\n",
        "Логично? Да. Но возникает еще одна проблема. Логарифм нельзя брать от отрицательного числа. Бороться с этим можно двумя способами.\n",
        "- Случай когда отрицательное число затисалось в target-ax не очень разумен, т. к. цена на дом не может быть отрицательной. В этом случае стоит кинуть ошибку, чтобы пользователь этой функции еще раз перепроверил правильные ли таргеты он подает.\n",
        "- В целом, у нас нет гарантий того, что наша модель (например линейная) предсказывает только положительные числа. Брать логарифм от отрицательного числа не получится, но качество такой модели все еще надо оценить. Давайте все предсказания, которые меньше некоторого порога $ a_{min} $, заменять этим порогом ($ \\hat{y_i} \\longleftarrow max(\\hat{y_i}, a_{min}) $), после чего подавать их в метрику. Для прохождения тестов возьмите $ a_{min} = 1 $.\n",
        "\n",
        "**2. Реализуйте эту метрику и сдайте в контест**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "OAgpUi26K1ur",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def root_mean_squared_logarithmic_error(y_true, y_pred, a_min=1.):\n",
        "    assert len(y_true) == len(y_pred), \"The length of true values and predicted values must be the same.\"\n",
        "    assert np.all(y_true >= 0), \"All true values must be non-negative.\"\n",
        "    \n",
        "    y_pred = np.maximum(y_pred, a_min)\n",
        "    return np.sqrt(np.mean((np.log(y_true) - np.log(y_pred)) ** 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSLE (no regularization) = 0.19510317164341626\n",
            "RMSLE (L1) = 0.1950407844483607\n",
            "RMSLE (L2) = 0.19503810952872347\n"
          ]
        }
      ],
      "source": [
        "print(\"RMSLE (no regularization) =\", root_mean_squared_logarithmic_error(Y_test, Y_pred_reg))\n",
        "print(\"RMSLE (L1) =\", root_mean_squared_logarithmic_error(Y_test, Y_pred_lasso))\n",
        "print(\"RMSLE (L2) =\", root_mean_squared_logarithmic_error(Y_test, Y_pred_ridge))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UABi31oTK1ur"
      },
      "source": [
        "### 4. Логарифмирование таргета."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yns3YwN-K1ur"
      },
      "source": [
        "Вообще идея с логарифмированием таргета довольно хороша для этой задачи. Давайте посмотрим на распределение обычных и логарифмированных таргетов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "JWb77b3uK1us",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_target_distribution(Y_train, Y_test, ax, n_bins=20):\n",
        "    ax.hist(Y_train, bins=n_bins, label=\"train\", color=\"red\", alpha=0.3, density=True)\n",
        "    ax.hist(Y_test, bins=n_bins, label=\"test\", color=\"blue\", alpha=0.3, density=True)\n",
        "\n",
        "    ax.legend()\n",
        "    ax.set_xlabel(\"Value\")\n",
        "    ax.set_ylabel(\"Probability\")\n",
        "\n",
        "\n",
        "def plot_both_distributions(Y_train, Y_test):\n",
        "    fig, (ax0, ax1) = plt.subplots(ncols=2, nrows=1, figsize=(15, 6))\n",
        "\n",
        "    plot_target_distribution(Y_train, Y_test, ax=ax0)\n",
        "    ax0.set_title(\"Standard\")\n",
        "\n",
        "    plot_target_distribution(np.log(Y_train), np.log(Y_test), ax=ax1)\n",
        "    ax1.set_title(\"Logarithmic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "IOkOnHqKK1uv",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_both_distributions(Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sdqyU7tK1uv"
      },
      "source": [
        "Как видите, если прологарифмировать таргеты, то их распределение станет более похоже на гауссовское. Интуиция подсказывает, что линейная регрессия с MSE loss-функцией должна лучше учиться на таких таргетах.\n",
        "\n",
        "Попробуйте написать класс, который во время обучения логарифмирует таргет, а во время предсказания — наоборот, экспоненциирует. После чего обучите оба метода на обучающих данных и сравните значения метрик MAE (Mean Squared Error) и MSLE (Mean squared logarithmic error) на тесте."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "exp(ln x) = x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qyR7QyiK1uv"
      },
      "source": [
        "Что должно быть в этом классе:\n",
        "- Класс должен называться ```ExponentialLinearRegression```\n",
        "- Класс должен иметь такой же fit-predict интерфейс, как и было до этого. На вход он получает оригинальные X и Y, а уже внутри происходит логарифмирование или экспоненциирование.\n",
        "- Внутри этой модели будет работать [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). Хочется, чтобы этому классу можно было передавать аргументы инициализации с помощью *args и **kwargs\n",
        "- Чтобы потом этот класс можно было использовать в [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) в следующих пунктах, у него должны быть реализованы 5 методов\n",
        "    1. ```__init__(self, *args, **kwargs)``` - все полученные аргументы передаются дальше в Ridge.\n",
        "    2. ```fit(self, X, Y)``` - обучает класс, возвращает self.\n",
        "    3. ```predict(self, X)``` - делает предсказание.\n",
        "    4. ```get_params(deep=True)``` - возвращает dict с параметрами модели. Больще подробностей [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
        "    5. ```set_params(**params)``` - передает нужные параметры в модель. Больше подробносте [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
        "- Есть два подхода к тому как сделать все нужные методы:\n",
        "    - Отнаследоваться от класса Ridge и переопределить методы fit и predict, внутри вызывая super() от отцовского класса.\n",
        "    - Отнаследоваться от класса RegressorMixin и внутренним атрибутом класса сделать Ridge. Тогда все методы нужно будет писать руками."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "IOnOVLY_K1uv",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class ExponentialLinearRegression(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, **params):\n",
        "        self.model = Ridge(**params) # Инициализация Ridge регрессора с переданными параметрами\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        Y_log = np.log(Y) # Логарифмируем таргет\n",
        "        self.model.fit(X, Y_log)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        Y_log = self.model.predict(X)\n",
        "        return np.exp(Y_log) # Экспоненцирование таргета (exp(ln x) = x)\n",
        "    \n",
        "    def get_params(self, *args, **kwargs):\n",
        "        return self.model.get_params(*args, **kwargs)\n",
        "\n",
        "    def set_params(self, *args, **kwargs):\n",
        "        self.model.set_params(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfGTYwdMK1uv"
      },
      "source": [
        "**3. Реализуйте этот класс и сдайте в контест**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "cBnuMKpTK1uv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE  : Classic : 23821.97776100681  Exponential : 26818.6997865444\n",
            "MSLE : Classic : 0.1950062123328133 Exponential : 0.21601027716185434\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "classic_regressor = Ridge()\n",
        "exponential_regressor = ExponentialLinearRegression()\n",
        "\n",
        "classic_regressor.fit(X_train, Y_train)\n",
        "exponential_regressor.fit(X_train, Y_train)\n",
        "\n",
        "classic_prediction = classic_regressor.predict(X_test)\n",
        "exponential_prediction = exponential_regressor.predict(X_test)\n",
        "\n",
        "print(f\"MAE  : Classic : {mean_absolute_error(Y_test, classic_prediction)}  Exponential : {mean_absolute_error(Y_test, exponential_prediction)}\")\n",
        "print(f\"MSLE : Classic : {root_mean_squared_logarithmic_error(Y_test, classic_prediction)} Exponential : {root_mean_squared_logarithmic_error(Y_test, exponential_prediction)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL9H6Fe0K1uw"
      },
      "source": [
        "Иногда получается так, что разные обученные вами модели приводят к улучшению одних метрик и ухудшению других. Это абсолютно нормально и этому не надо удивляться.\n",
        "\n",
        "Также зачастую случается так, что прирост по метрике не очень большой. И вы можете захотеть убедиться, что это реальное улучшение, а не просто случайная флуктуация. Для этого можно использовать подсчёт метрики про кросс-валидации (подробнее о ней можно почитать в соответствующей главе учебника). Суть метода в следующем:\n",
        "\n",
        "- мы разбиваем (случайным образом!) доступную нам выборку на $K$ (часто $K=5$) частей, которые называются _фолдами_\n",
        "- мы обучаем нашу модель $K$ раз, уча на всех фолдах, кроме одного, а на этом одном тестируя\n",
        "- мы получаем $K$ значений метрики, которые вместе дают нам лучшее представление о том, как ведёт себя модель на разных разбиениях на трейн и тест. В качестве итоговой метрики можно, к примеру, взять среднее полученных значений\n",
        "\n",
        "Сделать всё это можно с помощью обёртки [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), в которую можно подать модель, датасет и интересующую вас метрику. При этом оценку по кросс-валидации можно делать на всей доступной у вас выборке (ибо кросс-валидация уже включает разбиение на трейн и тест).\n",
        "\n",
        "Вычислите оценки MAE по кросс-валидации обычной (не регуляризованной) линейной регрессии и ExponentialLinearRegression на объединении обучающей и тестовой выборок.\n",
        "\n",
        "**4. Посчитайте и сдайте две оценки по кросс-валидации в Контест**.\n",
        "\n",
        "По шагам вам нужно\n",
        "1. Применить BaseDataPreprocessor к исходным данным\n",
        "2. Объединить трейн и тест\n",
        "3. Для первого числа использовать LinearRegression()\n",
        "4. Для второго -ExponentialLinearRegression с Ridge()\n",
        "5. Разбиение на фолды сделать с помощью `cv=KFold(n_splits=5, shuffle=True, random_state=42)`\n",
        "\n",
        "Обратите внимание, что параметр scoring — это не совсем функция-метрика, а немного более сложный объект, который можно соорудить, например, с помощью обёртки [make_scorer](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer).\n",
        "\n",
        "Также имейте в виду, что, вообще говоря, с дефолтным значением параметра `cv` кросс-валидация разбивает датасет на фолды детерминированным образом. Если вам нужно случайное разбиение, то в качестве cv стоит подать объект класса `sklearn.model_selection.KFold` или `sklearn.model_selection.StratifiedKFold`. Используйте\n",
        "\n",
        "```\n",
        "cv=KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtgOlv6tK1uw",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Также при написании кода для кросс-валидации вам может пригодиться знание о пайплайнах.\n",
        "\n",
        "Представьте ситуацию. Прошел месяц с того момента, как вы построили модель, а теперь вам надо дообучить её на новых данных и активно применять для предсказания. Если вы не позаботились об инфраструктуре, то вам придётся рыскать по всему ноутбуку в поисках того, как вы предобрабатывали данные, какую модель учили, обязательно что-нибудь забудете и будете очень страдать. Поэтому человечество придумало пайплайны, которые позволяют объединить предобработку данных и обучение модели в один класс - pipeline. Его можно писать самому, либо взять из sklearn ([link](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В библиотеке scikit-learn (или sklearn) модуль Pipeline используется для упрощения процесса создания и управления последовательностью шагов обработки данных и моделей машинного обучения. Он позволяет объединить несколько шагов в одну цепочку, что облегчает процесс построения и оценки моделей, особенно когда требуется выполнить несколько предобработок перед обучением модели.\n",
        "\n",
        "Как работает Pipeline?\n",
        "Pipeline состоит из последовательности шагов, каждый из которых представляет собой кортеж с именем шага и объектом, реализующим метод fit. Каждый шаг, кроме последнего, должен иметь метод transform, который будет применяться к данным. Последний шаг должен иметь метод fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "u3e3dNSaK1uw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean MAE (LinearRegression): 23222.643893618802\n",
            "Mean MAE (ExponentialLinearRegression): 21166.681537752724\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import make_scorer, mean_absolute_error\n",
        "\n",
        "mae_scorer = make_scorer(mean_absolute_error)\n",
        "\n",
        "# Объединение данных\n",
        "X_concatenated = np.concatenate((X_train, X_test), axis=0) # BaseDataPreprocessor уже применен к X_train, X_test выше\n",
        "Y_concatenated = np.concatenate((Y_train, Y_test), axis=0)\n",
        "\n",
        "# Создадим пайплайны\n",
        "pipeline_Linear = Pipeline([\n",
        "    # ('preprocessor', BaseDataPreprocessor()),         #Наши данные уже обработаны, поэтому повторного вызова BaseDataPreprocessor не требуется\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "pipeline_Exponential = Pipeline([\n",
        "    # ('preprocessor', BaseDataPreprocessor()),         #Наши данные уже обработаны, поэтому повторного вызова BaseDataPreprocessor не требуется\n",
        "    ('regressor', ExponentialLinearRegression())\n",
        "])\n",
        "\n",
        "# Кросс-валидация\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores_Linear = cross_val_score(pipeline_Linear, X_concatenated, Y_concatenated, cv=cv, scoring=mae_scorer)\n",
        "print(\"Mean MAE (LinearRegression):\", np.mean(scores_Linear))\n",
        "\n",
        "scores_Exponential = cross_val_score(pipeline_Exponential, X_concatenated, Y_concatenated, cv=cv, scoring=mae_scorer)\n",
        "print(\"Mean MAE (ExponentialLinearRegression):\", np.mean(scores_Exponential))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для сдачи контеста, нужно разкомментировать ('preprocessor', BaseDataPreprocessor()), и получить метрику 23226, но я не вижу смысла обрабатывать данные повторно. При нормализации данных мы теряем информацию, но делаем данные более равномерными, что зачастую хорошо для модели, но в данном случае, при повторной нормализации, данные становятся менее качественными, метрика МАЕ становится хуже (принцип less=good), поэтому я решил оставить #('preprocessor', BaseDataPreprocessor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjFgAA4YK1uw"
      },
      "source": [
        "### 5. Подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siKQL7pIK1uw"
      },
      "source": [
        "Линейную регрессию почти всегда можно улучшить с помощью регуляризации. Но при этом у нас возникает **гиперпараметр** — коэффициент регуляризации, и подбирать его нужно правильно. Более подробно о подборе гиперпараметров вы можете прочитать в соответствующей главе учебника), а пока мы разберём самые базовые подходы.\n",
        "\n",
        "В этой лабораторной вы познакомитесь с самым тривиальным способом — подбором по сетке. В данном случае это значит, что мы фиксируем несколько значений коэффициента регуляризации ```alpha``` и просто для каждого из них смотрим, что получится. Но важно отметить, что коэффициенты регуляризации стоит перебирать по _логарифмической_ сетке, например: `1e-2, 1e-1, 1, 1e+1, 1e+2`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Логарифмическая сетка называется так потому, что её масштабирование основано на логарифмических интервалах. Это означает, что значения на такой сетке распределены по логарифмической шкале, а не по линейной. Рассмотрим нашу сетку: `1e-2, 1e-1, 1, 1e+1, 1e+2`.\n",
        "\n",
        "В этой сетке значения соответствуют степеням числа 10:\n",
        "\n",
        "- \\(1e-2 = 10^{-2} = 0.01\\)\n",
        "- \\(1e-1 = 10^{-1} = 0.1\\)\n",
        "- \\(1 = 10^0 = 1\\)\n",
        "- \\(1e+1 = 10^1 = 10\\)\n",
        "- \\(1e+2 = 10^2 = 100\\)\n",
        "\n",
        "Между соседними значениями в логарифмической сетке существует одинаковый логарифмический шаг. Например:\n",
        "\n",
        "- \\(\\log_{10}(0.1) - \\log_{10}(0.01) = -1 - (-2) = 1\\)\n",
        "- \\(\\log_{10}(1) - \\log_{10}(0.1) = 0 - (-1) = 1\\)\n",
        "- \\(\\log_{10}(10) - \\log_{10}(1) = 1 - 0 = 1\\)\n",
        "- \\(\\log_{10}(100) - \\log_{10}(10) = 2 - 1 = 1\\)\n",
        "\n",
        "Каждое из этих интервалов в логарифмическом масштабе равно 1. Поэтому сетка распределена равномерно в логарифмическом масштабе, хотя в линейном масштабе расстояния между точками увеличиваются или уменьшаются экспоненциально.\n",
        "\n",
        "Такой подход удобен, например, при работе с данными, охватывающими широкий диапазон значений, поскольку он позволяет лучше визуализировать и анализировать данные, которые могут варьироваться от очень маленьких до очень больших чисел."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Разобравшись, что перебирать, перейдём к вопросу о том, как оценивать. Есть два основных подхода:\n",
        "\n",
        "*   Train-Val-Test split. Датасет делится на три части, на одной модели учатся, на другой подбираются гиперпараметры, на третьей считаются финальные метрики. Этот метод довольно шумный, зато быстрый.\n",
        "*   Кроссвалидация. Она значительно дольше, но надёжней. В этом пункте мы воспользуемся именно ей.\n",
        "\n",
        "\n",
        "Возьмите класс [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) из scikit-learn и с его помощью подберите гиперпараметр ```alpha``` для линейной регрессии с L2-регуляризацией (соответствующий класс зовут Ridge). Возможно, для минимизации разных метрик (_root_mean_squared_logarithmic_error_ и _mean_absolute_error_) понадобятся разные значения гиперпараметров. Выберите из сетки ```np.logspace(-3, 3, num=7, base=10.)``` значение, которое минимизирует _root_mean_squared_logarithmic_error_ для _ExponentialLinearRegression_ и\n",
        "\n",
        "**5. Загрузите оптимальное значение коэффициента регуляризации в Контест**.\n",
        "\n",
        "Параметр `cv` оставьте дефолтным или возьмите `cv=5` (результат не поменяется). Будьте внимательны: по умолчанию `best_score_` у `GridSearchCV` - это _самое большое значение_. Чтобы не попасться в эту ловушку, обратите внимание на параметр `greater_is_better` функции `make_scorer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "c_otnmqyK1uw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best alpha for RMSLE: 10.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rmsle_scorer = make_scorer(root_mean_squared_logarithmic_error, greater_is_better=False)\n",
        "\n",
        "pipeline_Exponential = Pipeline([\n",
        "    ('model', ExponentialLinearRegression())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'model__alpha': np.logspace(-3, 3, num=7, base=10.)\n",
        "}\n",
        "\n",
        "grid_search_rmsle = GridSearchCV(estimator=pipeline_Exponential, param_grid=param_grid, scoring=rmsle_scorer, cv=5)\n",
        "grid_search_rmsle.fit(X_train, Y_train)\n",
        "\n",
        "print(\"Best alpha for RMSLE:\", grid_search_rmsle.best_params_['model__alpha'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Почему мы использовали пайплайн, а не просто model = ExponentialLinearRegression()?\n",
        "\n",
        "Когда вы используете GridSearchCV с пайплайном, он автоматически обрабатывает внутренние шаги пайплайна и правильно передает параметры для настройки. Однако, когда вы передаете просто модель, GridSearchCV не знает, как правильно обрабатывать параметры модели, особенно если параметры находятся внутри пайплайна. Если вы передаете только модель, то GridSearchCV пытается применить параметры напрямую к модели, что может привести к ошибкам, если модель не инициализирована правильно или параметры не передаются корректно.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Почему мы использовали X_train, а не X_concatenated?\n",
        "\n",
        "В данном случае мы используем `X_train` и `Y_train` для настройки модели и поиска лучших гиперпараметров, поскольку цель `GridSearchCV` — выбрать наилучшие параметры модели на основе кросс-валидации на обучающем наборе данных. Вот почему использование `X_train` и `Y_train` является стандартной практикой:\n",
        "\n",
        "1. **Целостность данных:** При обучении и оценке модели, важно, чтобы данные для кросс-валидации и тестирования были независимыми. Если бы вы использовали весь набор данных (`X_train + X_test`) для кросс-валидации, это могло бы привести к переоценке модели, поскольку данные для кросс-валидации и для тестирования были бы перепутаны.\n",
        "\n",
        "2. **Кросс-валидация:** `GridSearchCV` разделяет данные `X_train` и `Y_train` на несколько подмножеств (фолдов) и выполняет кросс-валидацию. Это позволяет более надежно оценить производительность модели на различных подмножествах данных и избежать переобучения. Если бы вы использовали весь набор данных, то результат оценки мог бы быть неточным.\n",
        "\n",
        "3. **Тестирование:** После того как вы определили лучшие параметры с помощью `GridSearchCV` на обучающих данных, вы используете `X_test` и `Y_test` для окончательной оценки модели, чтобы получить представление о ее производительности на данных, которые модель не видела ранее.\n",
        "\n",
        "4. **Разделение данных:** Важно держать тестовые данные полностью вне процесса подбора гиперпараметров и кросс-валидации. Это гарантирует, что окончательная оценка модели будет объективной и не предвзятой.\n",
        "\n",
        "Поэтому, в процессе настройки модели и подбора гиперпараметров, мы используем только обучающий набор данных. `X_test` и `Y_test` используются отдельно для окончательной проверки производительности модели после того, как наилучшие гиперпараметры были выбраны."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUYa5U1gK1uw"
      },
      "source": [
        "### 6. Линейная модель своими руками\n",
        "\n",
        "В этом разделе вы напишете собственный класс линейной модели, чтобы лучше разобраться, как работает обучение с помощью SGD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-d2onzaK1uw"
      },
      "source": [
        "Линейная модель делает предсказание по такой формуле:\n",
        "$$\n",
        "\\hat{y_i} = \\langle \\vec{w}, \\vec{x_i} \\rangle + b\n",
        "$$\n",
        "Здесь $\\vec{w}$ и b - обучаемые параметры. $\\vec{x_i}$ - вектор фичей данного примера.\n",
        "$\\vec{w}$ и b находятся из задачи минимизации лосс функции:\n",
        "\n",
        "$$\n",
        "\\vec{w}, b = {argmin}_{\\vec{w}, b}(L) \\ ; \\ L = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2 + \\lambda \\vec{w}^T\\vec{w}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Наша лосс функция состоит из:\n",
        "\n",
        "1. MSE: \n",
        "   $$\n",
        "   \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 \n",
        "   $$\n",
        "\n",
        "2. L2 регуляризация: \n",
        "   $$\n",
        "   \\lambda \\vec{w}^T \\vec{w}\n",
        "   $$\n",
        "\n",
        "Почему формула L2 регуляризации такая, а не $\\lambda \\sum_{j=1}^{d} w_j^2$?\n",
        "\n",
        "Векторное представление $\\vec{w}^T\\vec{w}$ в лосс функции соответствует сумме квадратов элементов вектора $\\vec{w}$:\n",
        "\n",
        "- Пусть $\\vec{w}$ — это вектор $[w_1, w_2, \\ldots, w_d]$, где $d$ — количество фичей (размерность вектора).\n",
        "\n",
        "- Произведение $\\vec{w}^T \\vec{w}$ — это скалярное произведение вектора $\\vec{w}$ на себя:\n",
        "  $$\n",
        "  \\vec{w}^T \\vec{w} = w_1^2 + w_2^2 + \\ldots + w_d^2\n",
        "  $$\n",
        "\n",
        "Таким образом, выражение $\\lambda \\vec{w}^T \\vec{w}$ — это просто удобное матрично-векторное представление $L2$-регуляризации. Оно эквивалентно $\\lambda \\sum_{j=1}^{d} w_j^2$, что и есть штраф, добавляемый за большие значения весов, чтобы предотвратить переобучение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMisQdSGK1uw"
      },
      "source": [
        "Задачу минимизации лосс функции мы будем решать градиентным спуском. Для этого надо найти градиенты лосса по параметром модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaB_KihjK1uw"
      },
      "source": [
        "$$\n",
        "\\nabla_b L = \\frac{2}{N} sum(X \\vec{w} + b - \\vec{y})\\\\\n",
        "\\nabla_{\\vec{w}} L = \\frac{2}{N} X^T(X \\vec{w} + b - \\vec{y}) + 2\\lambda \\vec{w}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka0Q5OI6K1ux"
      },
      "source": [
        "Теперь давайте реализуем этот алгоритм ввиде класса с методами fit-predict.\n",
        "Что в нем должно быть:\n",
        "1. Класс должен называться ```SGDLinearRegressor```\n",
        "2. Класс должен быть отнаследован от sklearn-овского класса [RegressorMixin](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html)\n",
        "3. Класс должен инициализироваться со следующими гиперпараметрами:\n",
        "\n",
        "    a. ```lr``` — learning rate. Длина шага градиентного спуска\n",
        "\n",
        "    b. ```regularization``` — коэффициент λ из формулы выше\n",
        "    \n",
        "    c. ```delta_converged``` — устанавливает условие окончание обучение. В тот момент когда норма разности весов на соседних шагах градиентного спуска меньше чем ```delta_converged``` алгоритм перкращает обновлять веса\n",
        "    \n",
        "    d. ```max_steps``` — максимальное число шагов градиентного спуска\n",
        "    \n",
        "    e. ```batch_size``` — размер батча\n",
        "\n",
        "4. Реализуйте **стохастический** градиентный спуск. На каждом шагу градиентного спуска должен формироваться батч размера ```batch_size``` из матрицы признаков. Это нужно для того чтобы алгоритм быстрее сходился. Батч может выбираться случайно на каждом шаге градиентного спуска, либо каждую эпоху можно перемешивать трейн выборку и итерироваться батчами по ней."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFIb9mjWK1ux",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Обратите внимание при реализации SGD на следующие моменты (частые ошибки):\n",
        "* не перепутайте, какие коэффициенты в SGD стоят при самой функции потерь, а какие — при регуляризационном члене. Правильный вариант: $\\frac{\\alpha}{batch\\_size}$ при градиенте MSE, $\\alpha\\lambda$ при градиенте регуляризатора.\n",
        "* для остановки нужно сравнивать норму, а не ее квадрат\n",
        "* для правильного решения нужно не итерироваться по батчу,  а перемножать матрицы (иначе не зайдет по TL)\n",
        "* метод `predict` должен возвращать одномерный numpy array (не двумерный вектор-столбец формы (X.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "AYmQ4zSkK1ux",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class SGDLinearRegressor(RegressorMixin):\n",
        "    def __init__(self,\n",
        "                 lr=0.01, regularization=1., delta_converged=1e-3, max_steps=1000,\n",
        "                 batch_size=64):\n",
        "        self.lr = lr\n",
        "        self.regularization = regularization\n",
        "        self.max_steps = max_steps\n",
        "        self.delta_converged = delta_converged\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.W = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        n_samples, n_features = X.shape # n_samples - количество строк (количество примеров); n_features - количество признаков\n",
        "        # Инициализация весов и смещения\n",
        "        self.W = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        for step in range(self.max_steps):\n",
        "            # Перемешиваем данные для создания случайных батчей\n",
        "            indices = np.arange(n_samples) # аналог функции 'range' только создается одномерный массив \n",
        "            np.random.shuffle(indices) # перемешаем индексы\n",
        "            X_shuffled = X[indices]\n",
        "            Y_shuffled = Y[indices]\n",
        "\n",
        "            for start_idx in range(0, n_samples, self.batch_size): # от 0 до n_samples с шагом batch_size\n",
        "                end_idx = start_idx + self.batch_size\n",
        "                X_batch = X_shuffled[start_idx:end_idx]\n",
        "                Y_batch = Y_shuffled[start_idx:end_idx]\n",
        "\n",
        "                # Предсказание\n",
        "                Y_pred = np.dot(X_batch, self.W) + self.b\n",
        "                \n",
        "                # Вычисление градиентов\n",
        "                error = Y_pred - Y_batch\n",
        "                grad_w = (2 / self.batch_size) * np.dot(X_batch.T, error) + 2 * self.regularization * self.W\n",
        "                grad_b = (2 / self.batch_size) * np.sum(error)\n",
        "\n",
        "                # Обновление весов и смещения\n",
        "                self.W -= self.lr * grad_w\n",
        "                self.b -= self.lr * grad_b\n",
        "\n",
        "            # Проверка условия остановки\n",
        "            if np.linalg.norm(self.lr * grad_w) < self.delta_converged:\n",
        "                break\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.W) + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Понятие стохастического градиентного спуска\n",
        "\n",
        "- **Градиентный спуск** — это алгоритм оптимизации, используемый для минимизации функции потерь. Он обновляет параметры модели (например, веса) путем перемещения в направлении, противоположном градиенту функции потерь. Это позволяет находить минимум функции.\n",
        "\n",
        "- **Стохастический градиентный спуск (SGD)** — это разновидность градиентного спуска, в которой обновление параметров происходит для одного или нескольких случайно выбранных примеров из обучающего набора данных, а не для всех примеров. Это делает алгоритм более быстрым и позволяет избежать локальных минимумов за счет добавления \"шумов\" в процесс обновления.\n",
        "\n",
        "### Использование батчей\n",
        "\n",
        "- **Батч (Batch)** — это подмножество данных, которое используется для одного обновления параметров модели. Обучение с использованием батчей находится между двумя крайностями: полным градиентным спуском (использует весь набор данных за раз) и SGD (использует один пример за раз).\n",
        "\n",
        "- **Размер батча (batch size)** — это количество примеров, которые обрабатываются перед обновлением параметров модели. Например, если у вас 1000 примеров и размер батча равен 100, то за одну эпоху алгоритм сделает 10 шагов.\n",
        "\n",
        "### Алгоритм с батчами\n",
        "\n",
        "1. **Перемешивание данных**: На каждой эпохе или каждом шаге обучения данные перемешиваются, чтобы батчи были случайными. Это помогает избежать систематической ошибки, которая может возникнуть, если данные имеют какую-то внутреннюю упорядоченность.\n",
        "\n",
        "2. **Формирование батчей**: После перемешивания данные разбиваются на батчи фиксированного размера (`batch_size`). Каждый батч будет использоваться для вычисления градиентов и обновления параметров модели.\n",
        "\n",
        "3. **Обновление параметров**: Для каждого батча:\n",
        "   - Вычисляются предсказания модели.\n",
        "   - Вычисляется ошибка и градиенты функции потерь.\n",
        "   - Параметры модели обновляются с учетом вычисленных градиентов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "id": "DanmLPpaK1ux",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(586,) (586,)\n",
            "MAE :  25510.549825215567\n",
            "Mean log :  0.18862893826280525\n"
          ]
        }
      ],
      "source": [
        "# Check yourself\n",
        "model = SGDLinearRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "prediction = model.predict(X_test)\n",
        "print(Y_test.shape, prediction.shape)\n",
        "print(\"MAE : \", mean_absolute_error(Y_test, prediction))\n",
        "print(\"Mean log : \", root_mean_squared_logarithmic_error(Y_test, prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdVXFO2aK1ux"
      },
      "source": [
        "### 7. Категориальные признаки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npUKbcsbK1ux"
      },
      "source": [
        "В самом начале ноутбука мы отбросили категориальные фичи, хотя они могут помочь нам сделать модель лучше. Давайте же научимся ими пользоваться.\n",
        "\n",
        "Самый простой подход — это закодировать значения категориального признака числами, скажем, от $0$ до $C-1$, где $C$ — количество значений категориального признака. Иногда это может сработать, но для этого нужно, чтобы между значениями признака были определены отношения больше/меньше (такие признаки называются _ординальными_), причём соотношения между значениями должны быть более-менее линейными. В целом, не очень частая ситуация, поэтому так мы делать не будем.\n",
        "\n",
        "Вместо этого мы будем использовать OneHotEncoding. Пусть некоторая категориальная фича имеет $C$ уникальных значений. Давайте эту фичу закодируем в виде $C$ столбцов, каждый из которых соответствует некоторому уникальному значению категориальной фичи. Для каждого элемента выборки будем класть единичку в столбец, соответствующий этой фиче, и нолики в остальные.\n",
        "\n",
        "У этого метода есть недостаток. Если категориальная фича принимает слишком много значений, то вы нагенерируете много новых столбцов, каждый из которых будет содержать мало информации. Из-за них моделька может переобучиться.\n",
        "\n",
        "Этот метод имплементирован [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). У него есть пара важных гиперпараметров, которые стоит упомянуть:\n",
        "- ```handle_unknown``` - управляет обработкой незнакомых категорий на этапе `transform`. Число уникальных значений (и число столбцов) настраивается на обучающей выборке, и при дальнейшем применении может появиться значение, которого ещё не было. Если указать ```handle_unknown=\"ignore\"```, все поля для такого объекта будут заполнены нулями.\n",
        "- ```drop``` - если делать one-hot-encoding так как это описано выше, то сумма всех столбцов, соответствующих значениям категориальной фичи, будет равна единичному вектору. А такой вектор уже есть (он соответствует свободному члену). То есть признаки становятся линейно зависимыми, и это сломает процесс обучения линейной модели. Поэтому есть смысл для каждой фичи отбрасывать одну из получившихся колонок (```drop=\"first\"```) или хотя бы делать это только для бинарных фичей (```drop=\"if_binary\"```)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Подробнее о drop.\n",
        "\n",
        "### Что такое мультиколлинеарность?\n",
        "\n",
        "Мультиколлинеарность возникает, когда в наборе данных есть два или более признаков (столбца), которые сильно связаны между собой. В контексте линейных моделей это проблема, потому что модель не может четко определить, какой именно признак влияет на целевую переменную. В результате это может привести к нестабильным коэффициентам модели.\n",
        "\n",
        "### Почему возникает проблема с one-hot-encoding?\n",
        "\n",
        "Когда мы используем one-hot-encoding, мы создаем новый столбец для каждого возможного значения категориальной переменной. Например, если у нас есть переменная \"Цвет\" с тремя значениями: \"Красный\", \"Зеленый\", \"Синий\", то one-hot-encoding создаст три столбца. Каждый объект будет представлен как вектор с одной единицей и двумя нулями. Например:\n",
        "- \"Красный\" будет (1, 0, 0)\n",
        "- \"Зеленый\" будет (0, 1, 0)\n",
        "- \"Синий\" будет (0, 0, 1)\n",
        "\n",
        "Если у нас в наборе данных есть столбец-свободный член (например, константа 1), сумма этих столбцов для каждой строки всегда равна 1. Это и создает избыточность, так как мы можем предсказать значение любого из этих столбцов, зная другие.\n",
        "\n",
        "\n",
        "Проблема в том, что сумма всех этих векторов для любой строки будет равна 1, если у тебя есть столбец-свободный член в модели (например, столбец с единицами). Это создает линейную зависимость: один из этих векторов можно выразить через другие. Именно эта зависимость и называется мультиколлинеарностью, и она может осложнять обучение модели, особенно линейной, потому что модель не сможет различить влияние различных признаков на целевую переменную.\n",
        "\n",
        "### Пример с зависимостью\n",
        "\n",
        "Если у нас есть три столбца \"Цвет_Красный\", \"Цвет_Зеленый\" и \"Цвет_Синий\", то любой из них можно выразить через два других:\n",
        "\n",
        "- \"Цвет_Красный\" = 1 - (\"Цвет_Зеленый\" + \"Цвет_Синий\")\n",
        "\n",
        "Это значит, что информация в одном из этих столбцов полностью определяется информацией в других. Поэтому, чтобы избежать этой избыточности и обеспечить модель нужной информацией без зависимости, удаляют один из столбцов. В таком случае каждая категория по-прежнему будет однозначно идентифицироваться, но уже без линейной зависимости между признаками. \n",
        "\n",
        "### Преимущество удаления столбца\n",
        "\n",
        "Когда один столбец удален, например \"Цвет_Красный\", модель по оставшимся столбцам может однозначно определить все возможные категории:\n",
        "\n",
        "- (0, 0) будет \"Красный\"\n",
        "- (1, 0) будет \"Зеленый\"\n",
        "- (0, 1) будет \"Синий\"\n",
        "\n",
        "Эта методика исключает лишнюю информацию и делает обучение модели более стабильным.\n",
        "\n",
        "Таким образом, удаление одного столбца при one-hot-encoding помогает избежать проблемы мультиколлинеарности и делает модель более устойчивой и надежной."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0es5bKeK1ux"
      },
      "source": [
        "В этом пункте вам надо еще раз предобработать данные, добавив в них часть категориальных фичей, закодированных OneHotEncoding-ом. После этого обучите классификатор заново и выбейте лучшую метрику на тестовой выборке. А именно, мы добавим фичи \"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\". Используйте значение параметра handle_unknown=\"ignore\".\n",
        "\n",
        "*На практике в некоторых версиях scikit-learn есть проблема с совместимостью `handle_unknown=\"ignore\"` и `drop=\"first\"` одновременно, поэтому вторым можно пожертвовать.\n",
        "\n",
        "Класс будет наследоваться от BaseDataPreprocessor, так что в него можно будет передавать нужные для BaseDataPreprocessor параметры. Также это позволит не переписывать заново то, что происходит в базовом классе, а просто взывать к ним с помощью конструкции `super`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "GLKyWMP1K1ux",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "interesting_columns = [\"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\"]\n",
        "\n",
        "class OneHotPreprocessor(BaseDataPreprocessor):\n",
        "    def __init__(self, columns_to_encode: List[str], continue_columns: Optional[List[str]]):\n",
        "        super().__init__(needed_columns=continue_columns)\n",
        "        self.columns_to_encode = columns_to_encode\n",
        "        self.encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "    def fit(self, data: pd.DataFrame, *args):\n",
        "        # Fit the encoder only on the specified columns\n",
        "        self.encoder.fit(data[self.columns_to_encode])\n",
        "        # Fit the scaler using the parent class method \n",
        "        super().fit(data, *args) # Это для масштабирования числовых признаков.\n",
        "                                 # В родительском методе fit у BaseDataPreprocessor есть фильтрация needed_columns,\n",
        "                                 # так что ничего страшного в том, что мы передаем все данные (категориальные + числовые)\n",
        "        return self\n",
        "\n",
        "    def transform(self, data: pd.DataFrame) -> np.array:\n",
        "        # One-hot encode the specified columns\n",
        "        data_encoded = self.encoder.transform(data[self.columns_to_encode])\n",
        "        # Scale the other columns using the parent class method\n",
        "        data_scaled = super().transform(data) # Тут так же в методе transform у родительского класса BaseDataPreprocessor есть фильтрация needed_columns\n",
        "        # Concatenate the encoded and scaled data\n",
        "        return np.concatenate((data_encoded.toarray(), data_scaled), axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v80RppKdK1ux"
      },
      "source": [
        "Обучите модель с добавленными категориальными фичами. Получилось ли улучшить её качество?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSLE : 0.21601027716185434\n",
            "RMSLE (One hot encoder) : 0.18560982800718145\n"
          ]
        }
      ],
      "source": [
        "# Без кодирования\n",
        "model = ExponentialLinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "base_prediction = model.predict(X_test)\n",
        "print(\"RMSLE :\", root_mean_squared_logarithmic_error(Y_test, base_prediction))\n",
        "\n",
        "# C one hot кодированием\n",
        "ohe_preprocessor = OneHotPreprocessor(interesting_columns, continuous_columns)\n",
        "X_train_ohe = ohe_preprocessor.fit_transform(data_train)\n",
        "X_test_ohe = ohe_preprocessor.transform(data_test)\n",
        "\n",
        "model = ExponentialLinearRegression()\n",
        "model.fit(X_train_ohe, Y_train)\n",
        "\n",
        "ohe_prediction = model.predict(X_test_ohe)\n",
        "print(\"RMSLE (One hot encoder) :\", root_mean_squared_logarithmic_error(Y_test, ohe_prediction))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWYh1NPbK1uy"
      },
      "source": [
        "### 8. Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlzhlXoLK1uy"
      },
      "source": [
        "Представьте ситуацию. Прошел месяц с того момента, как вы построили модель, а теперь вам надо дообучить её на новых данных и активно применять для предсказания. Если вы не позаботились об инфраструктуре, то вам придётся рыскать по всему ноутбуку в поисках того, как вы предобрабатывали данные, какую модель учили, обязательно что-нибудь забудете и будете очень страдать. Поэтому человечество придумало пайплайны, которые позволяют объединить предобработку данных и обучение модели в один класс — pipeline. Его можно писать самому, либо взять из sklearn ([link](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)).\n",
        "\n",
        "**7. Напишите пайплайн, объединяющий использованную нами базовую предобработку данных (BaseDataPreprocessor и OneHotPreprocessor), а также линейную регрессию с L2-регуляризацией, и сдайте его в Контест.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "a6udrWyYK1uy",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def make_ultimate_pipeline(continuous_columns, categorical_columns):\n",
        "    one_hot_preprocessor = OneHotPreprocessor(columns_to_encode=categorical_columns, continue_columns=continuous_columns)\n",
        "    \n",
        "    # Пайплайн с двумя препроцессорами и линейной регрессией\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessorOneHot', one_hot_preprocessor), # Масштабирование данных числовых фичей включено\n",
        "        ('regressor', ExponentialLinearRegression())\n",
        "    ])\n",
        "    \n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSLE (Pipeline): 0.16879940919250203\n"
          ]
        }
      ],
      "source": [
        "pipeline = make_ultimate_pipeline(continuous_columns, categorical_columns)\n",
        "pipeline.fit(data_train, Y_train)\n",
        "y_pred = pipeline.predict(data_test)\n",
        "\n",
        "print(\"RMSLE (Pipeline):\", root_mean_squared_logarithmic_error(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ранее мы получили RMSLE (One hot encoder) : 0.18560982800718145 </br>\n",
        "Сейчас мы получили RMSLE (Pipeline): 0.16879940919250203\n",
        "\n",
        "Почему метрика стала чуть лучше?\n",
        "Возможно, потому что пайплайн может включать дополнительные шаги или оптимизации, которые неявно выполняются, например, правильное обращение с пропущенными значениями или кодирование категорий, которое отличается от ручного подхода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqmOG-epK1uz"
      },
      "source": [
        "В этом пункте вы попробуете сделать что-то поинтереснее и загрузите плоды ваших трудов в Контест.\n",
        "\n",
        "Попробуйте усовершенствовать предобработку данных, добавляя или выкидывая фичи, придумывая функции от признаков так, чтобы улучшить качество классификатора.\n",
        "\n",
        "Ещё несколько базовых идей о том, что можно было бы попробовать:\n",
        "\n",
        "- Постройте гистограммы значений признаков. Вы обнаружите, что некоторые из них почти всегда принимают одно и то же значение. Для начала их можно просто выкинуть.\n",
        "- Почистите выбросы. У некоторых объектов значения каких-то признаков могут сильно выбиваться, и это будет мешать регрессии обучиться. Вообще говоря, такие объекты можно выкидывать, но с текущей архитектурой пайплайна вам будет трудно это настроить. Так что вы можете пока заменять их на более разумные значения.\n",
        "- Мы добавили лишь несколько категориальных признаков, а на самом деле многие из них могут быть полезными.\n",
        "- Можно дискретизовать непрерывные фичи. Самый банальный пример: если непрерывная фича принимает всего несколько значений, её можно попробовать проинтерпретировать, как категориальную, и подать в one-hot энкодер. Но можно и как-то ещё разбивать по порогам.\n",
        "- Можно делать и более сложные преобразования. Например в датасете есть координаты квартиры, которые по идее сами по себе мало чего дают нашему регрессору. С другой стороны, по ним можно оценить центр города (или просто найти его на карте) и использовать в качестве фичи расстояние до центра города, которое может естественным образом влиять на цену жилья.\n",
        "- Не забывайте настраивать коэффициент регуляризации: для разных датасетов оптимальное значение будет разным.\n",
        "\n",
        "**В контест вам нужно будет сдать свой класс модели**. Он будет обучаться и тестироваться на новом и неизвестном вам разбиении датасета на трейн и тест по метрике `root_mean_squared_logarithmic_error`.\n",
        "В контесте будет специально проверено, что вы сдаёте именно `Pipeline`.\n",
        "\n",
        "Не забывайте, что вместе с пайплайном вам нужно отправить и все самописные классы, которые в нём участвуют.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
